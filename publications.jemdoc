# jemdoc: menu{MENU.txt}{Publications.html}
=Publications

Authors with \* contributed equally.


== 2025


- [https://miaolu3.github.io/publications.html Scaling Long-Horizon Agent via Context Folding] \n 
Weiwei Sun, *Miao Lu*, Zhan Ling, Xuesong Yao, Kang Liu, Yiming Yang, Jiecao Chen \n 
/Submitted/, Sep, 2025 \n

- [https://miaolu3.github.io/publications.html Scaling Multi-Turn LLM RL via End-to-End Summarization-based Context Management] \n 
*Miao Lu*, Weiwei Sun, Weihua Du, Zhan Ling, Xuesong Yao, Kang Liu, Jiecao Chen \n 
/Submitted/, Sep, 2025 \n

- [https://arxiv.org/pdf/2508.07571 Towards Theoretical Understanding of Transformer Test-Time Computing: Investigation on In-Context Linear Regression]\n
Xingwu Chen, *Miao Lu*, Beining Wu, Difan Zou \n
/NeurIPS Workshop on Foundations of Reasoning in Language Models (FoRLM) 2025/  \n 
/arXiv preprint/, Aug, 2025 \[[ArXiv_TTC.pdf *PDF*]\] \n

- [https://arxiv.org/abs/2502.06777  Learning an Optimal Assortment Policy under Observational Data]\n
Yuxuan Han, Han Zhong, *Miao Lu*, Jose Blanchet, Zhengyuan Zhou \n
/Under review in Management Science (MS)/ \n
/arXiv preprint/, Feb, 2025 \[[ArXiv_PRB.pdf *PDF*]\]  \n

- [https://openreview.net/forum?id=is4nCVkSFA Can Neural Networks Achieve Optimal Computational-Statistical Tradeoff? An Analysis on Single-Index Model]\n
Siyu Chen\*, Beining Wu\*, *Miao Lu*, Zhuoran Yang, Tianhao Wang \n
/NeurIPS Workshop on Mathematics of Modern Machine Learning (M3L) 2024/ *Oral*  \n 
/International Conference on Learning Representations (ICLR) 2025/ *Oral* \[[ICLR2025SingleIndex.pdf *PDF*]\] \[[M3L_slides.pdf *Slides*]\] \n



== Before 2025

- [https://arxiv.org/abs/2405.16436 Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer]\n 
Zhihan Liu\*, *Miao Lu\**, Shenao Zhang, Boyi Liu, Hongyi Guo, Yingxiang Yang, Jose Blanchet, Zhaoran Wang \n 
/ICML Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET) 2024/ \n
/Neural Information Processing Systems (NeurIPS) 2024/ \[[ArXiv_RPO.pdf *PDF*]\] \[[https://github.com/YSLIU627/Regularized-Preference-Optimization *Code*]\] \[[Poster_RPO.pdf *Poster*]\]\n

- [https://arxiv.org/abs/2404.03578 Distributionally Robust Reinforcement Learning with Interactive Data Collection: Fundamental Hardness and Near-Optimal Algorithm]\n 
*Miao Lu\**, Han Zhong\*, Tong Zhang, Jose Blanchet \n 
/ICML Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET) 2024/ \n
/Neural Information Processing Systems (NeurIPS) 2024/ \[[ArXiv_DRRL_Interactive.pdf *PDF*]\]  \[[NeurIPS2024IDCSlides.pdf *Slides*]\]\n

- [https://arxiv.org/abs/2310.17074 Benign Oscillation of Stochastic Gradient Descent with Large Learning Rates]\n 
*Miao Lu\**, Beining Wu\*, Xiaodong Yang, Difan Zou \n 
/NeurIPS Workshop on Mathematics of Modern Machine Learning (M3L) 2023/ \n
/International Conference on Learning Representations (ICLR) 2024/ \[[ArXiv_Benign_Oscillation.pdf *PDF*]\] \[[Benign_Oscillation_Poster.pdf *Poster*]\] \n

- [https://arxiv.org/abs/2305.18258 Maximize to Explore: One Objective Function Fusing Estimation, Planning, and Exploration]\n 
Zhihan Liu\*, *Miao Lu\**, Wei Xiong\*, Han Zhong, Hao Hu, Shenao Zhang, Sirui Zheng, Zhuoran Yang, Zhaoran Wang \n 
/Neural Information Processing Systems (NeurIPS) 2023/ *Spotlight*  (short version)  \n
/Under review in Operations Research (OR)  / (long version) \[[ArXiv_MEX.pdf *PDF*]\] \[[https://github.com/agentification/MEX *Code*]\] \[[NeurIPS2023MEX_Slides.pdf *Slides*]\]\n

- [https://arxiv.org/abs/2305.09659 Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage]\n 
Jose Blanchet, *Miao Lu*, Tong Zhang, Han Zhong (alphabetical) \n 
/Neural Information Processing Systems (NeurIPS) 2023/ (short version)\n
/Major revision in Mathematics of Operations Research (MOR)  / (long version)  \[[ArXiv_Double_Pessimism.pdf *PDF*]\] \[[NeurIPS2023DoublePessimism_Slides.pdf *Slides*]\]\n

- [https://arxiv.org/abs/2205.13589 Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes]\n
*Miao Lu*, Yifei Min, Zhaoran Wang, Zhuoran Yang \n
/International Conference on Learning Representations (ICLR) 2023/  \[[ArXiv_Pessimism_Confounded_POMDP.pdf *PDF*]\] \[[informs2022.pdf *Slides*]\]\n

- [https://proceedings.mlr.press/v162/liu22l.html Welfare Maximization in Competitive Equilibrium: Reinforcement Learning for Markov Exchange Economy]\n
Zhihan Liu\*, *Miao Lu\**, Zhaoran Wang, Michael I. Jordan, Zhuoran Yang \n
/International Conference on Machine Learning (ICML) 2022/ \[[ICML2022RLMEE.pdf *PDF*]\] \[[https://github.com/YSLIU627/RL-for-Markov-Exchange-Economy *Code*]\] \[[ICML2022RLMEE_Slides.pdf *Slides*]\]\n

- [https://openreview.net/forum?id=O1DEtITim__ Learning Pruning-Friendly Networks via Frank-Wolfe: One-Shot, Any-Sparsity, and No Retraining]\n
*Miao Lu\**, Xiaolong Luo\*, Tianlong Chen, Wuyang Chen, Dong Liu, Zhangyang Wang \n
/International Conference on Learning Representations (ICLR) 2022/ *Spotlight* \[[ICLR2022SFWPruning.pdf *PDF*]\] \[[https://github.com/VITA-Group/SFW-Once-for-All-Pruning *Code*]\]  \[[ICLR2022SFWPruning_Slides.pdf *Slides*]\]\n 

- [https://arxiv.org/abs/2112.10513 Learning Robust Policy against Disturbance in Transition Dynamics via State-Conservative Policy Optimization]\n
Yufei Kuang, *Miao Lu*, Jie Wang, Qi Zhou, Bin Li, Houqiang Li \n
/Association for the Advancement of Artificial Intelligence (AAAI) 2022/ \[[AAAI2022SCPO.pdf *PDF*]\] \[[https://github.com/MIRALab-USTC/RL-SCPO *Code*]\] \[[AAAI2022SCPO_Slides.pdf *Slides*]\]

