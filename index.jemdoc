# jemdoc: menu{MENU.txt}{index.html}
=Miao Lu

~~~
{}{img_left}{profile_seattle.png}{alt text}{325}{325}

*About Me*\n

Welcome to my homepage!

I am a Ph.D. candidate in Operations Research from [https://msande.stanford.edu the Department of Management Science and Engineering (MS&E)] at [https://www.stanford.edu Stanford University].
Prior to that, I obtained my Bachelor's degree in Probability and Statistics from the [http://en.ustc.edu.cn University of Science and Technology of China (USTC)], where I won the Guo Moruo scholarship, the highest honor awarding undergraduates of USTC.

*Research Interests*\n

My current research interest centers around reinforcement learning for LLM agents and training.

With backgrounds in probability and statistics, my past research includes mathematical theory and algorithm design of provably sample-efficient reinforcement learning, reinforcement learning from human feedback for LLM, training dynamics and generalization of optimization in deep learning landscapes, and reinforcement learning for operations and economics.

*Contact Information*\n

E-mail addresses: miaolu@stanford.edu, lumiao@mail.ustc.edu.cn\n

Here are my \[[https://scholar.google.com/citations?hl=en&user=3jS17zQAAAAJ&view_op=list_works&sortby=pubdate Google Scholar]\] \[[https://github.com/MiaoLu3 GitHub]\] \[[https://www.linkedin.com/in/miao-lu-5bb9a31aa LinkedIn]\] \[[Curriculum_Vitae.pdf CV]\]
~~~

== Industrial Experiences 

*ByteDance Seed*, San Jose, USA. /Jun. 2025 - Sep.2025/ 
- Researcher Scientist Intern in Foundations Models

*Ubiquant Investment*, Shanghai, China. /Jun. 2022 - Sep. 2022/
- Quantitative Research Intern in the AI Department

== Selected Publications  

- [https://arxiv.org/abs/2510.06727 Scaling Multi-Turn LLM RL via End-to-End Summarization-based Context Management] \n 
with Weiwei Sun, Weihua Du, Zhan Ling, Xuesong Yao, Kang Liu, Jiecao Chen \n 
/Submitted, Sep, 2025/ \n

- [https://arxiv.org/abs/2405.16436 Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer]\n 
with Zhihan Liu, Shenao Zhang, Boyi Liu, Hongyi Guo, Yingxiang Yang, Jose Blanchet, Zhaoran Wang \n 
/Neural Information Processing Systems (NeurIPS) 2024/ \n

- [https://arxiv.org/abs/2310.17074 Benign Oscillation of Stochastic Gradient Descent with Large Learning Rates]\n 
with Beining Wu, Xiaodong Yang, Difan Zou \n 
/International Conference on Learning Representations (ICLR) 2024/ \n

- [https://arxiv.org/abs/2305.18258 Maximize to Explore: One Objective Function Fusing Estimation, Planning, and Exploration]\n 
with Zhihan Liu, Wei Xiong, Han Zhong, Hao Hu, Shenao Zhang, Sirui Zheng, Zhuoran Yang, Zhaoran Wang \n 
/Neural Information Processing Systems (NeurIPS) 2023/ \n

- [https://arxiv.org/abs/2305.09659 Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage]\n 
with Jose Blanchet, Tong Zhang, Han Zhong \n 
/Neural Information Processing Systems (NeurIPS) 2023/ \n


