# jemdoc: menu{MENU.txt}{index.html}
=Miao Lu

~~~
{}{img_left}{profile_seattle.png}{alt text}{325}{325}

*About Me*\n

Welcome to my homepage!

I am a third-year Ph.D. candidate from [https://msande.stanford.edu the Department of Management Science and Engineering (MS&E)] at [https://www.stanford.edu Stanford University], advised by [https://joseblanchet.com Prof. Jose Blanchet].
I obtained my Bachelor's degree in Mathematics from the [http://en.ustc.edu.cn University of Science and Technology of China (USTC)].
Currently I am also a research scientist intern at NVIDIA Research. I previously interned at ByteDance Seed and Ubiquant Investment.

*Research Interests*\n

My recent research centers around reinforcement learning (RL) and LLM post-training.

With backgrounds in probability and statistics, my past research includes mathematical theory and algorithm design of RL, training dynamics and generalization properties of deep learning, and RL for operations and economics.

*Contact Information*\n

Email: miaolu [at] stanford [dot] edu

\[[https://scholar.google.com/citations?hl=en&user=3jS17zQAAAAJ&view_op=list_works&sortby=pubdate Google Scholar]\] \[[https://github.com/MiaoLu3 GitHub]\] \[[https://www.linkedin.com/in/miao-lu-5bb9a31aa LinkedIn]\] \[[Curriculum_Vitae.pdf CV]\]
~~~

== Selected Publications  


- [https://arxiv.org/abs/2510.06727 Scaling Multi-Turn LLM RL via End-to-End Summarization-based Context Management] \n 
with Weiwei Sun, Weihua Du, Zhan Ling, Xuesong Yao, Kang Liu, Jiecao Chen \n 
/Submitted, Sep, 2025/ \n

- [https://arxiv.org/abs/2510.11967 Scaling Long-Horizon LLM Agent via Context Folding] \n 
with Weiwei Sun, Zhan Ling, Xuesong Yao, Kang Liu, Yiming Yang, Jiecao Chen \n 
/Submitted, Sep, 2025/ \n

- [https://arxiv.org/abs/2602.10696 Robus Assortment Optimization from Observational Data]\n
with Yuxuan Han, Han Zhong, Zhengyuan Zhou, Jose Blanchet \n
/arXiv preprint, Feb, 2026/ \n

- [https://arxiv.org/abs/2405.16436 Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer]\n 
with Zhihan Liu, Shenao Zhang, Boyi Liu, Hongyi Guo, Yingxiang Yang, Jose Blanchet, Zhaoran Wang \n 
/Neural Information Processing Systems (NeurIPS) 2024/ \n

- [https://arxiv.org/abs/2310.17074 Benign Oscillation of Stochastic Gradient Descent with Large Learning Rates]\n 
with Beining Wu, Xiaodong Yang, Difan Zou \n 
/International Conference on Learning Representations (ICLR) 2024/ \n

- [https://arxiv.org/abs/2305.18258 Maximize to Explore: One Objective Function Fusing Estimation, Planning, and Exploration]\n 
with Zhihan Liu, Wei Xiong, Han Zhong, Hao Hu, Shenao Zhang, Sirui Zheng, Zhuoran Yang, Zhaoran Wang \n 
/Neural Information Processing Systems (NeurIPS) 2023/ \n

- [https://arxiv.org/abs/2305.09659 Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage]\n 
with Jose Blanchet, Tong Zhang, Han Zhong \n 
/Neural Information Processing Systems (NeurIPS) 2023/ \n


