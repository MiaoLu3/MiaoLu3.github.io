<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Miao Lu</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Homepage</div>
<div class="menu-item"><a href="index.html" class="current">About&nbsp;Me</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="experiences.html">Experiences</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Miao Lu</h1>
</div>
<table class="imgtable"><tr><td>
<img src="profile_seattle.png" alt="alt text" width="325px" height="325px" />&nbsp;</td>
<td align="left"><p><b>About Me</b><br /></p>
<p>Welcome to my homepage!</p>
<p>I am a third-year Ph.D. candidate from <a href="https://msande.stanford.edu">the Department of Management Science and Engineering (MS&amp;E)</a> at <a href="https://www.stanford.edu">Stanford University</a>, advised by <a href="https://joseblanchet.com">Prof. Jose Blanchet</a>.
I obtained my Bachelor's degree in Mathematics from the <a href="http://en.ustc.edu.cn">University of Science and Technology of China (USTC)</a>.
Currently I am also a research scientist intern at NVIDIA Research. I previously interned at ByteDance Seed and Ubiquant Investment.</p>
<p><b>Research Interests</b><br /></p>
<p>My recent research centers around reinforcement learning (RL) and LLM post-training.</p>
<p>With backgrounds in probability and statistics, my past research includes mathematical theory and algorithm design of RL, training dynamics and generalization properties of deep learning, and RL for operations and economics.</p>
<p><b>Contact Information</b><br /></p>
<p>Email: miaolu <a href="at">at</a> stanford <a href="dot">dot</a> edu</p>
<p>[<a href="https://scholar.google.com/citations?hl=en&amp;user=3jS17zQAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Google Scholar</a>] [<a href="https://github.com/MiaoLu3">GitHub</a>] [<a href="https://www.linkedin.com/in/miao-lu-5bb9a31aa">LinkedIn</a>] [<a href="Curriculum_Vitae.pdf">CV</a>]</p>
</td></tr></table>
<h2>Selected Publications  </h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2510.06727">Scaling Multi-Turn LLM RL via End-to-End Summarization-based Context Management</a> <br /> 
with Weiwei Sun, Weihua Du, Zhan Ling, Xuesong Yao, Kang Liu, Jiecao Chen <br /> 
<i>Submitted, Sep, 2025</i> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2510.11967">Scaling Long-Horizon LLM Agent via Context Folding</a> <br /> 
with Weiwei Sun, Zhan Ling, Xuesong Yao, Kang Liu, Yiming Yang, Jiecao Chen <br /> 
<i>Submitted, Sep, 2025</i> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2602.10696">Robust Assortment Optimization from Observational Data</a><br />
with Yuxuan Han, Han Zhong, Zhengyuan Zhou, Jose Blanchet <br />
<i>arXiv preprint, Feb, 2026</i> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2405.16436">Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer</a><br /> 
with Zhihan Liu, Shenao Zhang, Boyi Liu, Hongyi Guo, Yingxiang Yang, Jose Blanchet, Zhaoran Wang <br /> 
<i>Neural Information Processing Systems (NeurIPS) 2024</i> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2310.17074">Benign Oscillation of Stochastic Gradient Descent with Large Learning Rates</a><br /> 
with Beining Wu, Xiaodong Yang, Difan Zou <br /> 
<i>International Conference on Learning Representations (ICLR) 2024</i> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2305.18258">Maximize to Explore: One Objective Function Fusing Estimation, Planning, and Exploration</a><br /> 
with Zhihan Liu, Wei Xiong, Han Zhong, Hao Hu, Shenao Zhang, Sirui Zheng, Zhuoran Yang, Zhaoran Wang <br /> 
<i>Neural Information Processing Systems (NeurIPS) 2023</i> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2305.09659">Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage</a><br /> 
with Jose Blanchet, Tong Zhang, Han Zhong <br /> 
<i>Neural Information Processing Systems (NeurIPS) 2023</i> <br /></p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Copyright 2022 Miao Lu. Page generated 2026-02-11 23:28:22 PST.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
